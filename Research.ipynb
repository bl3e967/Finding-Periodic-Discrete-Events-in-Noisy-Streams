{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is taken from this [source](https://homepages.inf.ed.ac.uk/rsarkar/papers/periodic.pdf). It defines a model of discrete signals with approximately periodic sequences embedded in them. It includes a periodic component with probabilistic inter-event time, and a Poisson process modeling the aperiodic false positive noise events. \n",
    "\n",
    "Let $y_{1:n} = y_1, y_2, ..., y_n$ be our observed periodic signal. This can be decomposed into the following two components: \n",
    "\n",
    "- A sequence of periodic events $x_{i}$ where $x_{i+1} = N(x_i + T, \\sigma)$. Each signal event displays periodicity of time, $T$, along with gaussian noise parameterised by variance $\\sigma^2$.\n",
    "- A sequence of noise events $z_i$ where $z_{i+1} = z_i + \\delta$, and $\\delta$ follows an exponential distribution with an expectation of $\\frac{1}{\\lambda}$, for a rate parameter $\\lambda > 0$. This component takes into account noise attributed with the signal reading that can come from the signal itself or the instrument used to detect the signal. \n",
    "\n",
    "The model would be able to tell us the periodicity of the signal, $T$, along with $\\sigma$ and $\\lambda$ in order to characterise the level of noise in the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make the test data that will be used to validate our model. Some test cases that we can consider are: \n",
    "\n",
    "1. Just noise, no periodic signal: Can the model correctly identify that there is no signal?\n",
    "2. Strict periodic signal with no noise: baseline, the model should be able to correctly infer the peridicity of the signal with 100% certainty. \n",
    "3. Signal with probabilistic period.\n",
    "4. Periodic signal with phase drift. \n",
    "5. Periodic signal with random false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "SEED = 42 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our test data, let's implement the actual model. We will try and keep the variable naming consistent with the original [paper](https://homepages.inf.ed.ac.uk/rsarkar/papers/periodic.pdf). \n",
    "\n",
    "$$h_n = [T, \\sigma^2, \\lambda, \\hat{z_i}^j, \\hat{x_i}^j]^T$$\n",
    "\n",
    "where $i$ is the $i$ th timestep, and $j$ refers to the $j$ th particle that we have sampled, and: \n",
    "- T : period of signal\n",
    "- $\\sigma$ : standard deviation for Gaussion distribution of period variability. \n",
    "- $\\lambda$ : Rate of false positive noise events.\n",
    "- $\\hat{z}$ : Latest event timestep marked as a noise event.\n",
    "- $\\hat{x}$ : Latest event timestep marked as a periodic event. \n",
    "\n",
    "Each observed signal value $y_i$ can be classified as either the periodic signal or false positive noise. The model will therefore use variable $r_i$ where:\n",
    "$r_i = 1$ if $y_i$ originates from the periodic process, $r_i = 0$ otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Likelihood functions for signal, $L = p(y_i | h_i)$\n",
    "$L = p(y_i | h_i) = \\sum_{r \\in {0,1}}p(y_i, r_i | h_i)$\n",
    "\n",
    "Let's inspect the first component of the summation when $r_i = 1$. This component is the likelihood of the signal when it is generated by the periodic signal process. \n",
    "\n",
    "$p(y_i, r_i = 1 | h_i) = p(y_i | h_i, r_i = 1)p(r_i = 1)$\n",
    "\n",
    "and $p(y_i | h_i, r_i = 1)$ refers to the likelihood of the signal given it is generated by the periodic signal process. As mentioned above, we model this using Gaussian distribution centered about the timestamp of the last identified signal process offset by the period, $x_{i-1} + T_i$, with noise $\\sigma_i$:\n",
    "\n",
    "$p(y_i | h_i, r_i = 1) = N(T_i + \\hat{x}_{i-1}, \\sigma_i)$\n",
    "\n",
    "The term $p(r_i = 1)$ refers to the probability of $y_i$ not being a noise event. \n",
    "\n",
    "This is equivalent to: $1 - p(r_i = 0)$\n",
    "\n",
    "Given the false positive signal generation process follows a Poisson distribution, $p(r_i = 0)$ is equivalent to the probability that $y_i$ is the first noise process to be identified between the last identified false positive $z_{i-1}$ and $y_i$. The time between poission events is modelled by the exponential distribution, and the CDF of said distribution is $F(x) = 1 - exp(-\\lambda x)$. Hence, $1 - F(x) = exp(\\lambda x)$\n",
    "\n",
    "$$1 - p(r_i = 0) = 1 - F(y_i - z_{i-1}; exp(\\lambda_i)) = exp(\\lambda (y_i - z_{i-1}))$$ \n",
    "\n",
    "Now, let's inspect the second term of the summation when $r_i = 0$. This component is the likelihood of the signal when it is a false positive generated by noise. By definition of conditional probabilities, this can be rewritten as below: \n",
    "\n",
    "$$p(y_i, r_i = 0 | h_i) = p(y_i | r_i = 0, h_i) p(r_i = 0)$$\n",
    "\n",
    "We already have the second term, modelled by an exponential distribution $f_{\\exp}(x) = \\lambda exp(-\\lambda x)$. \n",
    "\n",
    "The first term is equivalent to the probability of no peridic signal event being detected between the last detected signal timestamp, $\\hat{x}_i$, and current signal timestamp $y_i$. This is approximated by the complementary cumulative density of periodic events between $\\hat{x}_i$ and $y_i$ - $1 - \\Phi(T_i + \\hat{x}_{i-1}, \\sigma_i)$, where $\\Phi(x) = P(X < x)$ is the Gaussian CDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hypothesis Updates\n",
    "Given our set of hypothesis in the algorithm's previous iteration, $h_{i-1}$, we now want to update them according to our prior over state changes, $p(h_i | h_{i-1})$.\n",
    "\n",
    "Each parameter contained in the Particle $h^{j}_{i}$ is sampled acacording to a Cauchy distribution centered around the previous parameter value. Taking parameter, $T$, as an example, $T_{i} \\sim Cauchy(T_i, s)$ where $s$ is a tuneable parameter. The same follos for $\\sigma$ and $\\lambda$. \n",
    "\n",
    "Parameters $\\hat{z}_{i-1}$ and $\\hat{x}_{i-1}$ are updated differently depending on the likelihood of $y_i$ being a false positive or not: $p(r_i | y_i, h_i)$. We can sample $r_i$ from this binomial distribution and update $\\hat{z}_{i-1}$ and $\\hat{x}_{i-1}$ accordingly: \n",
    "\n",
    "If $r_i = 1$, $\\hat{x}_{i} = y_i$ and $\\hat{z}_{i} = \\hat{z}_{i-1}$. \n",
    "\n",
    "If $r_i = 0$, $\\hat{x}_{i} = \\hat{x}_{i-1}$ and $\\hat{z}_{i} = y_i$\n",
    "\n",
    "We are able to calculate this distribution as below in terms of likelihod functions we already know: \n",
    "\n",
    "$p(r_i | h_i, y_i) = \\frac{p(r_i, y_i | h_i)}{p(y_i | h_i)} = \\frac{p(ri, y_i | h_i)}{p(y_i, r_i = 0 | h_i) + p(y_i, r_i = 1 | h_i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import ClassVar \n",
    "from scipy.stats import norm, expon\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    '''\n",
    "    Configuration object for periodicity particle filter\n",
    "    Args: \n",
    "        signal: the signal to be analyse\n",
    "        num_particles: number of particles to use\n",
    "        prior_T_scale: the hyperparameter to be used for the exponential distribution \n",
    "        that is used as the prior distribution for period T. \n",
    "        prior_lambda_scale: the hyperparameter to be used for the exponential distribution \n",
    "        that is used as the prior distribution for noise event rate Lambda.\n",
    "        x_0: initial value for periodic event variable\n",
    "        z_0: initial value for noise event variable\n",
    "        cauchy_scale: scale parameter for cauchy distribution used as the hypothesis distribution\n",
    "    '''\n",
    "    signal : list\n",
    "    num_particles : int = 50\n",
    "    prior_T_scale : float = 1.0\n",
    "    prior_lambda_scale : float = 1.0\n",
    "    x_0: float = 0.0 \n",
    "    z_0: float = 0.0\n",
    "    cauchy_scale : float = 1.0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.num_timesteps = len(self.signal)\n",
    "\n",
    "@dataclass\n",
    "class Particles:\n",
    "    '''\n",
    "    Dataclass for carrying around each variable defined in particle vector \n",
    "    h = [T, lambda, sigma, xhat, zhat]^t. \n",
    "    \n",
    "    Args: \n",
    "        T: \n",
    "        Lambda: Rate parameter for false positive signals due to noise. \n",
    "        Sigma:\n",
    "        X: timestamp of last identified signal generated by periodic signal process\n",
    "        Z: timestamp of last identified signal generated by false positive noise process\n",
    "        NumParticles: defaults to length of parameter vectors. Executes length typecheck. \n",
    "    '''\n",
    "    ### public ###\n",
    "    T : \"np.ndarray\"\n",
    "    Lambda : \"np.ndarray\"\n",
    "    Sigma : \"np.ndarray\"\n",
    "    X : \"np.ndarray\"\n",
    "    Z : \"np.ndarray\"\n",
    "    NumParticles : int\n",
    "\n",
    "    ### private class var ###\n",
    "\n",
    "    # number of params we use in our model\n",
    "    _NumParams : ClassVar[int] = 5\n",
    "\n",
    "    class VariableIndex(Enum):\n",
    "        T = 0\n",
    "        Lambda = 1\n",
    "        Sigma = 2\n",
    "        X = 3\n",
    "        Z = 4\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._assert_ctor_params_ndarray()\n",
    "        self._assert_ctor_params_same_len()\n",
    "        \n",
    "    def _assert_ctor_params_ndarray(self):\n",
    "        '''enforce type checking as a simple list does not support broadcasting\n",
    "        user must provide numpy arrays'''\n",
    "        assert isinstance(self.T, np.ndarray), \"T is not a numpy array\"\n",
    "        assert isinstance(self.Lambda, np.ndarray), \"Lambda is not a numpy array\"\n",
    "        assert isinstance(self.Sigma, np.ndarray), \"Sigma is not a numpy array\"\n",
    "        assert isinstance(self.X, np.ndarray), \"X is not a numpy array\"\n",
    "        assert isinstance(self.Z, np.ndarray), \"Z is not a numpy array\"\n",
    "\n",
    "    def _assert_ctor_params_same_len(self):\n",
    "        \n",
    "        is_same_len = (len(self.T)  \\\n",
    "                      == len(self.Lambda) \\\n",
    "                      == len(self.Sigma) \\\n",
    "                      == len(self.X) \\\n",
    "                      == len(self.Z) \\\n",
    "                      == self.NumParticles)\n",
    "        \n",
    "        assert is_same_len, f\"Input vectors are not of the same size. Size specified is {self.NumParticles}\"\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.NumParticles \n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return  np.array_equal(self.T, other.T) \\\n",
    "                and np.array_equal(self.Lambda, other.Lambda) \\\n",
    "                and np.array_equal(self.Sigma, other.Sigma) \\\n",
    "                and np.array_equal(self.X, other.X) \\\n",
    "                and np.array_equal(self.Z, other.Z)\n",
    "\n",
    "    @staticmethod \n",
    "    def _indexing_key_typecheck(key):\n",
    "        if not (isinstance(key, int) or isinstance(key, slice) or isinstance(key, np.ndarray)):\n",
    "            raise TypeError(f\"Particles object behaves as a 1-D array or list. Invalid index of type {type(key)}\")\n",
    "\n",
    "    def _indexing_out_of_bounds_check(self, key):\n",
    "        if (isinstance(key, slice)): \n",
    "            if key.stop > self.NumParticles - 1:\n",
    "                raise IndexError(f\"Particles object contains {self.NumParticles} particles. Cannot retrieve items for indices {key.start}:{key.stop}\")\n",
    "\n",
    "        elif isinstance(key, int):\n",
    "            if (key > self.NumParticles -1):\n",
    "                raise IndexError(f\"Particles object contains {self.NumParticles} particles. Cannot retrieve items for index {key}\")\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        self._indexing_key_typecheck(key)\n",
    "        self._indexing_out_of_bounds_check(key)\n",
    "\n",
    "        t = self.T[key]\n",
    "        l = self.Lambda[key]\n",
    "        s = self.Sigma[key]\n",
    "        x = self.X[key]\n",
    "        z = self.Z[key]\n",
    "\n",
    "        if isinstance(key, int):\n",
    "            N = 1\n",
    "            # input needs to be np array\n",
    "            t, l, s, x, z = np.array([t]), np.array([l]), np.array([s]), np.array([x]), np.array([z])\n",
    "        else:\n",
    "            N = len(t)\n",
    "\n",
    "        return Particles(t, l, s, x, z, N)\n",
    "\n",
    "    def __setitem__(self, key, value:\"Particles\"):\n",
    "        self._indexing_key_typecheck(key)\n",
    "        self._indexing_out_of_bounds_check(key)\n",
    "\n",
    "        if not isinstance(value, Particles):\n",
    "            raise TypeError(f\"Value to be set should be Particles object, not {type(value)}\")\n",
    "\n",
    "        self.T[key] = value.T \n",
    "        self.Lambda[key] = value.Lambda \n",
    "        self.Sigma[key] = value.Sigma \n",
    "        self.X[key] = value.X \n",
    "        self.Z[key] = value.Z \n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        self._indexing_key_typecheck(key)\n",
    "        self._indexing_out_of_bounds_check(key)\n",
    "        self.T.__delitem__(key)\n",
    "        self.Lambda.__delitem__(key)\n",
    "        self.Sigma.__delitem__(key)\n",
    "        self.X.__delitem__(key)\n",
    "        self.Z.__delitem__(key)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx in range(self.NumParticles):\n",
    "            yield Particles(self.T[idx], \n",
    "                            self.Lambda[idx], \n",
    "                            self.Sigma[idx], \n",
    "                            self.X[idx], \n",
    "                            self.Z[idx])\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (self._NumParams, self.NumParticles)\n",
    "\n",
    "    @property\n",
    "    def X_last(self):\n",
    "        return self._X_last\n",
    "\n",
    "    @X_last.setter\n",
    "    def X_last(self, val):\n",
    "        '''enforce type checking as a simple list does not support broadcasting\n",
    "        user must provide numpy arrays'''\n",
    "        assert isinstance(val, np.ndarray), \"X_last is not a numpy array\"\n",
    "        self._X_last = val \n",
    "\n",
    "    @property\n",
    "    def Z_last(self):\n",
    "        return self._Z_last\n",
    "\n",
    "    @Z_last.setter\n",
    "    def Z_last(self, val):\n",
    "        '''enforce type checking as a simple list does not support broadcasting\n",
    "        user must provide numpy arrays'''\n",
    "        assert isinstance(val, np.ndarray), \"X_last is not a numpy array\"\n",
    "        self._Z_last = val\n",
    "\n",
    "    def as_matrix(self):\n",
    "        '''Return np.ndarray of vector h = [T, lambda, sigma, xhat, zhat]^t\n",
    "        of shape (5, num_particles)'''\n",
    "        return np.stack((self.T, self.Lambda, self.Sigma, self.X, self.Z))\n",
    "\n",
    "class PeriodicityParticleFilter:\n",
    "    def __init__(self, config:Config):\n",
    "        self.config = config\n",
    "        self.y = config.signal\n",
    "        self.num_timesteps = self.config.num_timesteps\n",
    "        self.K = self.config.num_particles\n",
    "        self.s_T = self.config.prior_T_scale \n",
    "        self.s_lambda = self.config.prior_lambda_scale\n",
    "        self.s_cauchy = self.config.cauchy_scale\n",
    "\n",
    "        self._h = None\n",
    "        self._iter_cnt = 0\n",
    "\n",
    "    def signal(self):\n",
    "        '''\n",
    "        Generator method for iterating through the signal. \n",
    "        Returns the next value in the signal. \n",
    "        '''\n",
    "        while True: \n",
    "            yield self.y[self._iter_cnt]\n",
    "            self._iter_cnt += 1\n",
    "\n",
    "    def initialise_samples(self) -> Particles:\n",
    "        '''\n",
    "        Sample K particles from prior distributions for h_0\n",
    "        h = [T, lambda, sigma, x_0, z_0] \n",
    "        where: \n",
    "            T ~ exponential(scale) \n",
    "            lambda ~ exponential(scale)\n",
    "            sigma ~ Uniform(0, T)\n",
    "            x_0 = zero\n",
    "            z_0 = zero\n",
    "        '''\n",
    "        T_0 = np.random.exponential(self.s_T, self.K)\n",
    "        lambda_0 = np.random.exponential(self.s_lambda, self.K) \n",
    "        sigma_0 = np.random.rand(self.K) * T_0\n",
    "        x_0 = np.zeros(self.K)\n",
    "        z_0 = np.zeros(self.K) \n",
    "        return Particles(T_0, lambda_0, sigma_0, x_0, z_0, self.K)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_cauchy_1D(loc, scale):\n",
    "        hnew_std = np.random.standard_cauchy(len(loc))\n",
    "        hnew = scale * hnew_std + loc \n",
    "        return hnew\n",
    "\n",
    "    def sample_event_provenance(self, y, h:Particles):\n",
    "        '''\n",
    "        Sample event provenance r_i. \n",
    "        Args: \n",
    "            h: Particles object, containing particles (or hypotheses) used in our model.\n",
    "\n",
    "        Returns: \n",
    "            r: r values sampled from bernoulli distribution. Size is equal to number of \n",
    "            particles. \n",
    "\n",
    "        Calculate bernoulli distribution, p(r_i = val | y_i, h_i), using conditional probabilities:\n",
    "\n",
    "        p(ri = 1 | yi, hi) = PeriodicSignalLikelihood / (PeriodicSignalLikelihood + FalsePositiveLikelihood)\n",
    "        p(ri = 0 | yi, hi) = 1 - p(ri = 1 | yi, hi)\n",
    "        '''\n",
    "        \n",
    "        ps = self.get_periodic_likelihood(y, h)\n",
    "        fp = self.get_false_positive_likelihood(y, h)\n",
    "\n",
    "        p = ps / (ps + fp)\n",
    "        \n",
    "        # single trial binomial = bernoulli\n",
    "        N = 1 \n",
    "        r = np.random.binomial(N, p)\n",
    "\n",
    "        return r\n",
    "        \n",
    "\n",
    "    def update_hypothesis(self, y, h:Particles):\n",
    "        '''\n",
    "        Sample next set of particles from hypothesis distribution p(h_i|h_{i-1}).\n",
    "        For the ith timestep, let j denote the jth particle:\n",
    "        h^j = [T^j, lambda^j, sigma^j, x_j, z_j]\n",
    "\n",
    "        where each variable in vector h_j are sampled from a cauchy distribution centred\n",
    "        about the previous particle value. \n",
    "        '''\n",
    "        # sample T, lambda, sigma from cauchy\n",
    "        # hnew_std = np.random.standard_cauchy() # scale = s, mean = 0\n",
    "        # hnew = self.s_cauchy * hnew_std + h # scale = s, mean = h\n",
    "        # take absolute value as these params need to be > 0\n",
    "        h.T = np.abs(self.sample_cauchy_1D(h.T, self.s_cauchy))\n",
    "        h.Sigma = np.abs(self.sample_cauchy_1D(h.Sigma, self.s_cauchy))\n",
    "        h.Lambda = np.abs(self.sample_cauchy_1D(h.Lambda, self.s_cauchy))\n",
    "\n",
    "        rsampled = self.sample_event_provenance(y, h)\n",
    "        r_is_1_idx, r_is_0_idx = np.nonzero(rsampled), np.nonzero(1-rsampled)\n",
    "        h.X[r_is_1_idx] = y \n",
    "        h.Z[r_is_0_idx] = y \n",
    "        \n",
    "        return h\n",
    "\n",
    "    def get_periodic_likelihood(self, y, h:Particles):\n",
    "        '''\n",
    "        The likelihood of the signal being generated by the signal process. \n",
    "\n",
    "        L = p(yi, ri=1|hi) = p(yi | hi, ri = 1) x (1 - p(ri = 0)) \n",
    "        = N(Ti + x_{i-1}, sigma_i) * (1 - F(yi - z_{i-1}; exp(lambda_i)))\n",
    "\n",
    "        Args: \n",
    "            y : ith event timestamp\n",
    "            h : particle object containing current parameter hypotheses \n",
    "        '''\n",
    "        \n",
    "        # p(yi | hi, ri=1) = N(Ti + x_{i-1}, sigma_i)\n",
    "        p1 = norm.pdf(y, h.T + h.X, h.Sigma)\n",
    "        \n",
    "        # 1 - F(yi - z_{i-1}; exp(lambda_i)); F_exp(x; lambda) = 1 - exp(-lamba * x)\n",
    "        # therefore, 1 - F(yi - z_{i-1}; exp(lambda_i)) = exp(-lambda * (yi - z_{i-1}))\n",
    "        p2 = np.exp(-h.Lambda * (y - h.Z))\n",
    "\n",
    "        return p1 * p2 \n",
    "\n",
    "    def get_false_positive_likelihood(self, y, h:Particles):\n",
    "        '''\n",
    "        The likelihood of the signal being a false positive generated by noise. \n",
    "\n",
    "        L = p(yi, ri = 0 | hi) = p(i | hi, ri = 0) x p(ri = 0) \n",
    "        = f(yi - z_{i-1}; exp(lambda_i)) * (1 - F(yi; N(x_{i-1} + Ti, sigma_i)))\n",
    "\n",
    "        Args: \n",
    "            y: ith event timestamp\n",
    "            h: particle object containing current parameter hypotheses. \n",
    "        '''\n",
    "        # f(yi - z_{i-1}; exp(lambda_i)), expon takes parameter scale = 1/lambda\n",
    "        p1 = expon.pdf(y - h.Z, scale=1 / h.Lambda)\n",
    "        \n",
    "        # 1 - Phi(y; x_{i-1} + Ti, sigma_i)\n",
    "        p2 = 1 - norm.cdf(y, loc = h.T + h.X, scale = h.Sigma)\n",
    "\n",
    "        return p1 * p2 \n",
    "\n",
    "    def likelihood_weighting(self, y, h:Particles):\n",
    "\n",
    "        # Lper = p(yi, ri=1 | hi)\n",
    "        Lperiodic = self.get_periodic_likelihood(y, h)\n",
    "\n",
    "        # Lfp = p(yi, ri0 | hi)\n",
    "        Lfp = self.get_false_positive_likelihood(y, h)\n",
    "\n",
    "        # L = p(yi | hi) = p(yi, ri=0 | hi) + p(yi, ri=1 | hi)\n",
    "        L = Lperiodic + Lfp\n",
    "        \n",
    "        return L\n",
    "\n",
    "    def resample_particles(self, h:Particles, w:np.ndarray):\n",
    "        '''\n",
    "        Resample particles, h, with probabilities according to their likelihood weights, w. \n",
    "        The number of particles resampled, k, is equal to the number of particles present in the \n",
    "        Particles object (equivalent to len(h)). k is equivalent to self.K, or config.num_particles. \n",
    "\n",
    "        Args: \n",
    "            h: Particles object\n",
    "            w: np.array of length equal to the number of particles\n",
    "        \n",
    "        Raises ValueError if length of w does not equal to the number of particles. \n",
    "        Raises ValueError if length of h is not equal to self.K (which is eqv to config.num_particles).\n",
    "        '''\n",
    "        num_h = len(h)\n",
    "\n",
    "        if (num_h != len(w)):\n",
    "            msg = \"Number of particles must match length of array of weights.\" + \\\n",
    "                f\"Received Particles object of length {num_h} but likelihood weights given is \" + \\\n",
    "                    f\"of length {len(w)}\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        if (num_h != self.K):\n",
    "            msg = f\"Number of particles specified for this model is {self.K}, but Particles object\" + \\\n",
    "                f\" given has {num_h} particles.\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        idx = np.random.choice(a=num_h, size=num_h, replace=True, p=w)\n",
    "        h = h[idx]\n",
    "\n",
    "        return h \n",
    "\n",
    "    def fit(self):\n",
    "        '''Run the particle filter on the input data.'''\n",
    "\n",
    "        # initialise K particles by sampling from prior distributions \n",
    "        # over hypothesis parameters. \n",
    "        self._h = self.initialise_samples()\n",
    "\n",
    "        for y in self.signal(): \n",
    "            # sample next set of particles from hypothesis distribution p(h_i|h_{i-1})\n",
    "            self._h = self.update_hypothesis(y, self._h)\n",
    "\n",
    "            # likelihood weighting - compute likeliness of each particle\n",
    "            lw = self.likelihood_weighting(y, self._h)\n",
    "\n",
    "            # normalise likelihood weights \n",
    "            lw_norm = lw / np.sum(lw)\n",
    "\n",
    "            # resample\n",
    "            self._h = self.resample_particles(self._h, lw_norm)\n",
    "\n",
    "        return self._h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### unit tests ### \n",
    "\n",
    "# Test particle ctor\n",
    "def test_nd_array_check():\n",
    "\n",
    "    def _check(T, Lambda, sigma, xlast, zlast, N, expectedmsg):\n",
    "        try: \n",
    "            example_h = Particles(T, \n",
    "                                  Lambda, \n",
    "                                  sigma, \n",
    "                                  xlast,\n",
    "                                  zlast,\n",
    "                                  N) \n",
    "        except AssertionError as e:\n",
    "            expected = str(e) == expectedmsg\n",
    "            if not expected: \n",
    "                raise AssertionError(f\"Expected error message: '{expectedmsg}' but received {str(e)}\")\n",
    "            return \n",
    "\n",
    "        raise AssertionError(\"Input type check for np.ndarray did not trigger an assertion error.\" + \n",
    "                             f\" Expected to see error msg: {expectedmsg}\")\n",
    "\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([100, 100, 100, 100])\n",
    "    example_Z_last = np.array([0, 0, 0, 0])\n",
    "    N = 4\n",
    "    \n",
    "    expectedmsg = \"T is not a numpy array\"\n",
    "    _check(list(example_T), example_lambda, example_sigma, example_X_last, example_Z_last, N, expectedmsg)\n",
    "\n",
    "    expectedmsg = \"Lambda is not a numpy array\"\n",
    "    _check(example_T, list(example_lambda), example_sigma, example_X_last, example_Z_last, N, expectedmsg)\n",
    "\n",
    "    expectedmsg = \"Sigma is not a numpy array\"\n",
    "    _check(example_T, example_lambda, list(example_sigma), example_X_last, example_Z_last, N, expectedmsg)\n",
    "\n",
    "    expectedmsg = \"X is not a numpy array\"\n",
    "    _check(example_T, example_lambda, example_sigma, list(example_X_last), example_Z_last, N, expectedmsg)\n",
    "\n",
    "    expectedmsg = \"Z is not a numpy array\"\n",
    "    _check(example_T, example_lambda, example_sigma, example_X_last, list(example_Z_last), N, expectedmsg)\n",
    "\n",
    "\n",
    "def test_arr_length_check():\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([100, 100, 100])\n",
    "    example_Z_last = np.array([0, 0, 0])\n",
    "    N = 4\n",
    "    \n",
    "    try: \n",
    "        example_h = Particles(example_T, \n",
    "                            example_lambda, \n",
    "                            example_sigma, \n",
    "                            example_X_last,\n",
    "                            example_Z_last,\n",
    "                            N)\n",
    "    except AssertionError as e:\n",
    "        expectedmsg = \"\"\n",
    "        expected = str(e) == expectedmsg\n",
    "        if expected: \n",
    "            raise AssertionError(f\"Expected error message: '{expectedmsg}' but received {str(e)}\")\n",
    "        return\n",
    "\n",
    "    raise AssertionError(\"input length check did not trigger an assertion error\")\n",
    "\n",
    "def test_len():\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([100, 100, 100, 100])\n",
    "    example_Z_last = np.array([0, 0, 0, 0])\n",
    "    N = 4\n",
    "\n",
    "    example_h = Particles(example_T, \n",
    "                        example_lambda, \n",
    "                        example_sigma, \n",
    "                        example_X_last,\n",
    "                        example_Z_last,\n",
    "                        N)\n",
    "\n",
    "    assert len(example_h) == N, f\"Expected len(Particle) to return {N}, but got {len(example_h)} instead\"\n",
    "\n",
    "def test_shape():\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([100, 100, 100, 100])\n",
    "    example_Z_last = np.array([0, 0, 0, 0])\n",
    "    N = 4\n",
    "\n",
    "    example_h = Particles(example_T, \n",
    "                        example_lambda, \n",
    "                        example_sigma, \n",
    "                        example_X_last,\n",
    "                        example_Z_last,\n",
    "                        N)\n",
    "\n",
    "    expected_shape = (5, N)\n",
    "    assert example_h.shape == expected_shape, f\"Expected Particle.shape property to return {expected_shape}, \" + \\\n",
    "                                              f\"but got {example_h.shape} instead\"\n",
    "\n",
    "def test_as_matrix():\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([100, 100, 100, 100])\n",
    "    example_Z_last = np.array([0, 0, 0, 0])\n",
    "    N = 4\n",
    "\n",
    "    example_h = Particles(example_T, \n",
    "                        example_lambda, \n",
    "                        example_sigma, \n",
    "                        example_X_last,\n",
    "                        example_Z_last,\n",
    "                        N)\n",
    "\n",
    "    h_mat = example_h.as_matrix()\n",
    "\n",
    "    assert h_mat.shape == (5, N), f\"as_matrix() method returned a matrix of shape {h_mat.shape}. \" + \\\n",
    "        f\"Expected shape of {(5,N)}\"\n",
    "\n",
    "    expected = np.stack((example_T, example_lambda, example_sigma, example_X_last, example_Z_last))\n",
    "\n",
    "    assert np.array_equal(h_mat, expected), \"as_matrix() returned a value that was not expected.\"\n",
    "\n",
    "def test_particle_eq():\n",
    "\n",
    "    t = np.array(range(0,10))\n",
    "    l = np.array(range(0,10)) * 2 # multiply just to differentiate values for each var \n",
    "    s = np.array(range(0,10)) * 3\n",
    "    x = np.array(range(0,10)) * 4 \n",
    "    z = np.array(range(0,10)) * 5\n",
    "\n",
    "    h1 = Particles(t, l, s, x, z, len(t))\n",
    "    h2 = Particles(t, l, s, x, z, len(t))\n",
    "\n",
    "    assert h1 == h2, f\"Test case 1: __eq__ method check returned False when True was expected.\"\n",
    "\n",
    "    t = np.array(range(0,10)) * 100\n",
    "    l = np.array(range(0,10)) * 2 # multiply just to differentiate values for each var \n",
    "    s = np.array(range(0,10)) * 3\n",
    "    x = np.array(range(0,10)) * 4 \n",
    "    z = np.array(range(0,10)) * 5\n",
    "\n",
    "    h3 = Particles(t, l, s, x, z, len(t))\n",
    "\n",
    "    assert h1 != h3, f\"Test case 2: __eq__ method check returned True when False was expected.\"\n",
    "\n",
    "    t = np.array([1])\n",
    "    l = np.array([1])\n",
    "    s = np.array([1])\n",
    "    x = np.array([1])\n",
    "    z = np.array([1])\n",
    "    h4 = Particles(t, l, s, x, z, 1)\n",
    "    h5 = Particles(t, l, s, x, z, 1)\n",
    "\n",
    "    assert h4 != h1, \"Test case 3: __eq__ method check returned True when False was expected.\"\n",
    "    assert h4 != h2, \"Test case 4: __eq__ method check returned True when False was expected.\"\n",
    "    assert h4 != h3, \"Test case 5: __eq__ method check returned True when False was expected.\"\n",
    "    assert h4 == h5, f\"Test case 6: __eq__ method check returned False when True was expected.\"\n",
    "\n",
    "\n",
    "def test_particle_getitem():\n",
    "    N = 10\n",
    "    t = np.array(range(0,N))\n",
    "    l = np.array(range(0,N)) * 2 # multiply just to differentiate values for each var \n",
    "    s = np.array(range(0,N)) * 3\n",
    "    x = np.array(range(0,N)) * 4 \n",
    "    z = np.array(range(0,N)) * 5\n",
    "\n",
    "    h = Particles(t, l, s, x, z, len(t))\n",
    "\n",
    "    # test out of index for integer index \n",
    "    try: \n",
    "        M = N + 100\n",
    "        h[N]\n",
    "        raise AssertionError(f\"Expected Particles[{M}] to raise IndexError as Particles \" + \\\n",
    "            f\"object contains {M} particles, but no IndexError was raised\")\n",
    "    except IndexError as e: \n",
    "        pass \n",
    "\n",
    "    # test out of index for slice\n",
    "    try: \n",
    "        sidx, eidx = int(N/2), N + 100\n",
    "        h[sidx:eidx]\n",
    "        raise AssertionError(f\"Expected Particles[{sidx}:{eidx}] to raise IndexError as Particles \" + \\\n",
    "            f\"object contains {M} particles, but no IndexError was raised\")\n",
    "    except IndexError as e:\n",
    "        pass \n",
    "\n",
    "    # test integer index \n",
    "    for i in range(-3, N):\n",
    "        expected = Particles(np.array([t[i]]), \n",
    "                             np.array([l[i]]), \n",
    "                             np.array([s[i]]), \n",
    "                             np.array([x[i]]), \n",
    "                             np.array([z[i]]), \n",
    "                             1)\n",
    "        msg = f\"{i}: Expected {h[i]} to be equal to {expected} but __eq__ returned False\"\n",
    "        assert h[i] == expected,  msg\n",
    "\n",
    "    sidx = 0\n",
    "    eidx = 3\n",
    "    expected = Particles(np.array(t[sidx:eidx]), \n",
    "                         np.array(l[sidx:eidx]), \n",
    "                         np.array(s[sidx:eidx]), \n",
    "                         np.array(x[sidx:eidx]), \n",
    "                         np.array(z[sidx:eidx]),\n",
    "                         eidx - sidx)\n",
    "    got = h[sidx:eidx]\n",
    "    assert got == expected, f\"Expected {expected} but received {got} for Particles[{sidx}:{eidx}]\"\n",
    "\n",
    "    sidx = -3\n",
    "    eidx = -1\n",
    "    expected = Particles(np.array(t[sidx:eidx]), \n",
    "                         np.array(l[sidx:eidx]), \n",
    "                         np.array(s[sidx:eidx]), \n",
    "                         np.array(x[sidx:eidx]), \n",
    "                         np.array(z[sidx:eidx]),\n",
    "                         2)\n",
    "    got = h[sidx:eidx]\n",
    "    assert got == expected, f\"Expected {expected} but received {got} for Particles[{sidx}:{eidx}]\"\n",
    "\n",
    "def test_particle_setitem():\n",
    "    N = 10\n",
    "    t = np.ones(N)\n",
    "    l = np.ones(N)\n",
    "    s = np.ones(N)\n",
    "    x = np.ones(N)\n",
    "    z = np.ones(N)\n",
    "\n",
    "    h = Particles(t, l, s, x, z, len(t))\n",
    "\n",
    "    # set single index\n",
    "    arr = np.ones(N)\n",
    "    for idx in range(-3,N):\n",
    "        h[idx] = Particles(np.zeros(1),np.zeros(1),np.zeros(1),np.zeros(1),np.zeros(1),1)\n",
    "        arr[idx] = 0\n",
    "        expected = Particles(arr, arr, arr, arr, arr, N)\n",
    "        assert h == expected, f\"Expected {expected} but got {h} when setting Particles[{idx}]\"\n",
    "\n",
    "        assert np.array_equal(h.T, arr), f\"Expected h.T to give {arr} but got {h.T}\"\n",
    "        assert np.array_equal(h.Lambda,arr), f\"Expected h.Lambda to give {arr} but got {h.Lambda}\"\n",
    "        assert np.array_equal(h.Sigma,arr), f\"Expected h.Sigma to give {arr} but got {h.Sigma}\"\n",
    "        assert np.array_equal(h.X,arr), f\"Expected h.X to give {arr} but got {h.X}\"\n",
    "        assert np.array_equal(h.Z,arr), f\"Expected h.Z to give {arr} but got {h.Z}\"\n",
    "\n",
    "    # set using slice\n",
    "    t = np.ones(N)\n",
    "    l = np.ones(N)\n",
    "    s = np.ones(N)\n",
    "    x = np.ones(N)\n",
    "    z = np.ones(N)\n",
    "\n",
    "    h = Particles(t, l, s, x, z, len(t)) # reset \n",
    "    sidx, eidx = 3,6\n",
    "    n = eidx - sidx \n",
    "    tmp = np.ones(n) * 100\n",
    "    h[sidx:eidx] = Particles(tmp, tmp, tmp, tmp, tmp, n)\n",
    "    arr = np.ones(N)\n",
    "    arr[sidx:eidx] = 100\n",
    "\n",
    "    assert np.array_equal(h.T, arr), f\"Expected h.T to give {arr} but got {h.T}\"\n",
    "    assert np.array_equal(h.Lambda,arr), f\"Expected h.Lambda to give {arr} but got {h.Lambda}\"\n",
    "    assert np.array_equal(h.Sigma,arr), f\"Expected h.Sigma to give {arr} but got {h.Sigma}\"\n",
    "    assert np.array_equal(h.X,arr), f\"Expected h.X to give {arr} but got {h.X}\"\n",
    "    assert np.array_equal(h.Z,arr), f\"Expected h.Z to give {arr} but got {h.Z}\"\n",
    "\n",
    "    # set usng slice with neatices \n",
    "\n",
    "def test_particle_container_properties():\n",
    "    test_particle_eq()\n",
    "    test_particle_getitem()\n",
    "    test_particle_setitem()\n",
    "\n",
    "test_particle_container_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "### unit tests ## \n",
    "\n",
    "# Test function - get_periodic_likelihood\n",
    "\n",
    "def test_periodic_likelihood_no_noise():\n",
    "    '''\n",
    "    Test case: \n",
    "\n",
    "    Let's have the signal as strictly periodic where the true\n",
    "    period T = 100;\n",
    "    \n",
    "    i.e. signal timestamps = 0, 100, 200, 300, 400, 500,...\n",
    "\n",
    "    Here, true lambda = 0 (rate of false positive = 0 as we have none)\n",
    "    and true sigma = 0 (signal is strictly periodic with no uncertainty)\n",
    "\n",
    "    For our particle vector h = [T, lambda, sigma, X, Z], let's have the following samples: \n",
    "\n",
    "    For this test case, y_{i-1} = 100, y_i = 200\n",
    "\n",
    "    particles for test scenario: \n",
    "\n",
    "    h1 = [T = 100, lambda = 0, sigma = 0, x_last = 100, z_last = 0]\n",
    "    This should return NaN. T = 100 is correct with zero uncertainty. sigma=0, so gaussian pdf \n",
    "    would have an infinite pdf value. Lambda = 0 so correct that we have no noise, and we also\n",
    "    correctly know no noise has been found yet, z_last = 0. \n",
    "\n",
    "    h2 = [T = 100, lambda = 0, sigma = 0.01, x_last = 100, z_last = 0]\n",
    "    Same as test 1, but now with non-zero uncertainty. This should return a non-NaN likelihood value \n",
    "    as the gaussian no longer has a divide by zero. Exact value is: 39.89422804\n",
    "    \n",
    "    h3 = [T = 1, lambda = 0, sigma = 0.01, x_last = 100, z_last = 0]\n",
    "    T is way off, with small uncertainty. x_last = 100 while current value is 200. \n",
    "    This means likelihood of the observation generated by a periodic signal according to particle h3 is zero. \n",
    "    Again, noise process param lambda is set to zero. \n",
    "\n",
    "    h4 = [T = 90, lambda = 0, sigma = 25, x_last = 100, z_last = 0]\n",
    "    T is a bit off, but sigma = 25 so that actual T falls within 1 std dev of our estimate. \n",
    "    Likelihood should be moderate value. Actual value is 0.014730805\n",
    "    '''\n",
    "    y_prev = 100\n",
    "    y_curr = 200\n",
    "    example_T = np.array([100, 100, 1, 90])\n",
    "    example_lambda = np.array([0, 0, 0, 0])\n",
    "    example_sigma = np.array([1e-19, 0.01, 0.01, 25])\n",
    "    example_X_last = np.array([y_prev, y_prev, y_prev, y_prev])\n",
    "    example_Z_last = np.array([0, 0, 0, 0])\n",
    "    \n",
    "    example_h = Particles(example_T, \n",
    "                         example_lambda, \n",
    "                         example_sigma, \n",
    "                         example_X_last,\n",
    "                         example_Z_last,\n",
    "                         4) # Z_curr not used in priodic likelihood so just set to zero\n",
    "\n",
    "    # initialisation does not matter, we're just testing the get_periodic_likelihood func. \n",
    "    particle_filter = PeriodicityParticleFilter(Config([]))\n",
    "\n",
    "    p = particle_filter.get_periodic_likelihood(y_curr, example_h)\n",
    "\n",
    "    p1, p2, p3, p4 = p \n",
    "    p1_expected, p2_expected, p3_expected, p4_expected = 18.6, 39.9, 0, 0.014731\n",
    "\n",
    "    assert np.round(np.log10(p1), 1) == p1_expected, f\"Expected {p1_expected} for test case 1, but received {p1}\"\n",
    "    assert np.round(p2, 1) == p2_expected, f\"Expected {p2_expected} for test case 2, but received {p2}\"\n",
    "    assert np.round(p3, 12) == p3_expected, f\"Expected {p3_expected} for test case 3, but received {p3}\"\n",
    "    assert np.round(p4, 6) == p4_expected, f\"Expected {p4_expected} for test case 4, but received {p4}\"\n",
    "\n",
    "\n",
    "def test_periodic_likelihood_with_noise():\n",
    "    '''\n",
    "    Test case: \n",
    "\n",
    "    Let's have the signal as periodic where the true period T = 100,\n",
    "    with noise that occurs within 25 time units. Example signal could look like:\n",
    "    \n",
    "    i.e. signal timestamps = 0, 10, 100, 117, 200, 214, 300, 313, 400, 415, 500,...\n",
    "\n",
    "    For our particle vector h = [T, lambda, sigma, X, Z], let's have the following samples: \n",
    "\n",
    "    h1 = [T = 100, lambda = ln(2)/100, sigma = 1E-19, x_last = 200, z_last = 114]\n",
    "    We set the particle T = 100 and sigma = 1E-19 - i.e. this particle is close to the actual true signal\n",
    "    parameters. We should get a zero value for the peridic series likelihood as the parameters indicate we are most certain\n",
    "    that the period of the true signal is 100 with almost zero uncertainty, therefore 214 being a true signal is impossible. \n",
    "    We've set the current and last noise signal times to be 114 and 214; we set the lambda to ln(2)/100 such that 100 becomes \n",
    "    the half-life of our exponential distribution. We should get a pdf value of 0.5 * f_exp(0) = 0.5 * lambda ~= .0034657 from the exponential distribution. \n",
    "    Therefore, as the false-positve likelihood is expon-pdf * (1 - Phi), we will expect a fp value close to 0.0034657. \n",
    "\n",
    "    h2 = [T = 100, lambda = ln(2)/100, sigma = 86, x_last = 200, z_last = 114]\n",
    "    Similar setup to first particle, h1, but now the uncertainty for the periodic signal has been increased, such that the \n",
    "    214 y_curr value now falls within 1 std dev (next expected periodic signal is at 300, but std dev is now set to 86). \n",
    "    We should expect a higher liklihood now for the periodic model. \n",
    "    For the noise model, we still expect a likelihood close to 0.0034657, but lower as now the probability of this signal being noise is \n",
    "    offset by the uncertainty now introduced by sigma (refer to Likelihood Functions section). \n",
    "    '''\n",
    "    z_last = 114\n",
    "    y_prev = 200\n",
    "    y_curr = 214\n",
    "\n",
    "    example_T = np.array([100, 100])\n",
    "    example_lambda = np.array([np.log(2)/100, np.log(2)/100])\n",
    "    example_sigma = np.array([1e-19, 86])\n",
    "    example_X_last = np.array([y_prev, y_prev])\n",
    "    example_Z_last = np.array([z_last, z_last])\n",
    "\n",
    "    example_h = Particles(example_T, \n",
    "                         example_lambda, \n",
    "                         example_sigma, \n",
    "                         example_X_last,\n",
    "                         example_Z_last, \n",
    "                         2) # Z_curr not used in priodic likelihood so just set to zero\n",
    "\n",
    "    # initialisation does not matter, we're just testing the get_periodic_likelihood func. \n",
    "    particle_filter = PeriodicityParticleFilter(Config([]))\n",
    "\n",
    "    p_periodic = particle_filter.get_periodic_likelihood(y_curr, example_h)\n",
    "    p_fp = particle_filter.get_false_positive_likelihood(y_curr, example_h)\n",
    "\n",
    "    p_per_1, p_per_2 = p_periodic\n",
    "    p_fp_1, p_fp_2 = p_fp\n",
    "\n",
    "    p_per_1_expected, p_per_2_expected = 0.0, 0.0014068\n",
    "    p_fp_1_expected, p_fp_2_expected = np.log(2)/100 * 0.5, 0.0029159\n",
    "\n",
    "    # periodic series likelihood assertions\n",
    "    assert p_per_1 == p_per_1_expected, f\"Expected periodic likelihood = {p_per_1_expected} for test case 1, but got {p_per_1} instead\"\n",
    "    assert np.round(p_per_2,7) == p_per_2_expected, f\"Expected periodic likelihood = {p_per_2_expected} for test case 2, but got {np.round(p_per_2,7)} instead\"\n",
    "    \n",
    "    # false positive likelihood assertions\n",
    "    assert p_fp_1 == p_fp_1_expected, f\"Expected false posiive likelihood = {p_fp_1_expected} for test case 1, but got {p_fp_1} instead\"\n",
    "    assert np.round(p_fp_2, 7) == p_fp_2_expected, f\"Expected false positive likelihood = {p_fp_2_expected} for test case 2, but got {np.round(p_fp_2, 7)} instead\"\n",
    "\n",
    "def test_event_provenance_sampling():\n",
    "    '''\n",
    "    Test our method for updating our Xi and Zi parameters according to the event\n",
    "    provenance variable ri. \n",
    "\n",
    "    Test case 1:\n",
    "    hi = [T = 100, lambda = 0, sigma = 1e-19, xlast = 100, zlast = 100]\n",
    "    The parameters set for this particle are indicating that we are very sure that the current \n",
    "    observation is generated from our periodic signal while there is no change of it being a false positive.\n",
    "    Therefore, bernoulli distrbution p will be equal to 1. Hence, we should get r = 1. \n",
    "\n",
    "    Test case 2: \n",
    "    hi = [T = 100, lambda = np.log(2)/50, sigma = 1e19, xlast = 100, zlast = 150]\n",
    "    This particle has parameters for periodc signal likelihood set with period 100 \n",
    "    and large sigma. Hence, periodic signal likelihood will be ~0.  \n",
    "    \n",
    "    Meanwhile, last Z observed is set to 150. We set lambda to ln(2)/50 such that ycurr=200 is the half life \n",
    "    of the exponential distribution pdf. Therefore, false positive likelihood given ri = 0 is = ln(2)50*0.5 = 0.006931471805599453. \n",
    "    p(ri = 0) = 1 - gausscdf(100, 100, 1e19), where gauss cdf = 0.5. So, false positive likelihood = 0.00693 * 0.5\n",
    "\n",
    "    Therefore, overall bernoulli p = 0 / (0 + 0.003465...) = 0, so we should get r = 0. \n",
    "\n",
    "    Test case 3: \n",
    "    hi = [T = 100, lambda = np.log(2)/10, sigma = 25, xlast = 175, zlast = 190]\n",
    "\n",
    "    Periodic signal model is way off, and so p_periodic_given_signal_is_periodic will be = 0. \n",
    "    False positive model parameter lambda is set to ln(2)/10 such that p_fp_given_signal_is_fp = ln(2)/10 * 0.5. \n",
    "    Given these parameters, periodic model is somewhat uncertain of whether current observation is \n",
    "    periodic, and the same for the false positive model. Given the setup, the likelihood of this\n",
    "    being a false positive is greater (i.e. bernoulli p < 0.5) so we tend to get more zeros for r.\n",
    "    Given the seed, we get a zero.\n",
    "\n",
    "    Test case 4: \n",
    "    hi= [T = 10, lambda= np.log(2)/5, sigma = 7, xlast = 191, zlast = 195]\n",
    "\n",
    "    ycurr = 200 and period is 10, xlast is 191 with sigma = 7 so a new signal is due soon. \n",
    "    ycurr = 200 and lambda is np.log(2)/10 is the half life of the exponential given zlast = 195. \n",
    "    The setup should be unclear to the model whether the signal is periodic or a false positive.\n",
    "    p value that we get is close to 0.5. Given the seed 0, we get a r value of 1. \n",
    "    '''\n",
    "    ycurr = 200\n",
    "    example_T = np.array([100, 100, 100, 10])\n",
    "    example_lambda = np.array([1e-19, np.log(2)/50, np.log(2)/10, np.log(2)/10])\n",
    "    example_sigma = np.array([1e-19, 1e19, 50, 10])\n",
    "    example_X_last = np.array([100, 100, 175, 191])\n",
    "    example_Z_last = np.array([0, 150, 190, 195])\n",
    "    N = 4\n",
    "\n",
    "    example_h = Particles(example_T, \n",
    "                         example_lambda, \n",
    "                         example_sigma, \n",
    "                         example_X_last, # X_curr not used in priodic likelihood so just set to zero \n",
    "                         example_Z_last, \n",
    "                         N) # Z_curr not used in priodic likelihood so just set to zero\n",
    "\n",
    "    example_h.X_last = example_X_last\n",
    "    example_h.Z_last = example_Z_last\n",
    "\n",
    "    # initialisation does not matter. \n",
    "    particle_filter = PeriodicityParticleFilter(Config([]))\n",
    "\n",
    "    np.random.seed(2) # sampling is random so seed it\n",
    "    r = particle_filter.sample_event_provenance(ycurr, example_h)\n",
    "    r1, r2, r3, r4 = r\n",
    "    \n",
    "    assert r1 == 1, f\"Test 1: Expected r = {1} but got r = {r1}\"\n",
    "    assert r2 == 0, f\"Test 2: Expected r = {0} but got r = {r2}\"\n",
    "    assert r3 == 0, f\"Test 3: Expected r = {0} but got r = {r3}\"\n",
    "    assert r4 == 1, f\"Test 4: Expected r = {1} but got r = {r3}\"\n",
    "\n",
    "def test_particle_resampling():\n",
    "    n = 1000\n",
    "    T = np.array(range(0,n))\n",
    "    L = np.array(range(0,n))\n",
    "    S = np.array(range(0,n))\n",
    "    X = np.array(range(0,n))\n",
    "    Z = np.array(range(0,n))\n",
    "    \n",
    "    h = Particles(T, L, S, X, Z, n)\n",
    "    pf = PeriodicityParticleFilter(Config([], num_particles=n))\n",
    "    \n",
    "    # Test Case 1: \n",
    "    # Weights are 1 for idx = 0, else 0. h returned should only contain values from h[0]\n",
    "    w1 = np.zeros(n)\n",
    "    w1[0] = 1\n",
    "\n",
    "    h1 = pf.resample_particles(h, w1)\n",
    "\n",
    "    msg = f\"Expected resampled particle to be all zeros, but received {h1}\"\n",
    "    assert np.array_equal(h1.as_matrix(), np.zeros(shape=(5,n))), msg\n",
    "\n",
    "    # Test Case 2: \n",
    "    # Weights are equal - sampling should be from uniform distribution \n",
    "    np.random.seed(0)\n",
    "    w2 = np.ones(n) / n\n",
    "    h2 = pf.resample_particles(h, w2)\n",
    "\n",
    "    res = scipy.stats.kstest(h2.T, 'uniform', N=n) # all var's have same value so we can use just T\n",
    "\n",
    "    # we are very certain this should be uniform so set expected pvalue to zero\n",
    "    assert res.pvalue == 0.0, \"Particles resampling should have uniform distribution, \" + \\\n",
    "        f\"but p-value for goodness-of-fit test aganst uniform distribution returned {res.pvalue}, not 0.0\"\n",
    "    \n",
    "    \n",
    "    # Test Case 3: \n",
    "    # Weights are normally distributed\n",
    "    w3 = scipy.stats.norm.pdf(np.linspace(-3,3,n))\n",
    "    w3 = w3 / np.sum(w3)\n",
    "    h3 = pf.resample_particles(h, w3)\n",
    "\n",
    "    res = scipy.stats.kstest(h3.T, 'norm', N=n)\n",
    "\n",
    "    # we are very certain this should be normal so set expected pvalue to zero\n",
    "    assert res.pvalue == 0.0, \"Particles resampling should have normal distribution, \" + \\\n",
    "        f\"but p-value for goodness-of-fit test aganst normal distribution returned {res.pvalue}, not 0.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected periodic likelihood = 0.0014068 for test case 2, but got 0.0004372 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=10'>11</a>\u001b[0m     test_particle_resampling()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll tests passed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=13'>14</a>\u001b[0m execute_all_tests()\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 15'\u001b[0m in \u001b[0;36mexecute_all_tests\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=6'>7</a>\u001b[0m test_particle_container_properties()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=7'>8</a>\u001b[0m test_periodic_likelihood_no_noise()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=8'>9</a>\u001b[0m test_periodic_likelihood_with_noise()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=9'>10</a>\u001b[0m test_event_provenance_sampling()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000014?line=10'>11</a>\u001b[0m test_particle_resampling()\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 14'\u001b[0m in \u001b[0;36mtest_periodic_likelihood_with_noise\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000013?line=129'>130</a>\u001b[0m \u001b[39m# periodic series likelihood assertions\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000013?line=130'>131</a>\u001b[0m \u001b[39massert\u001b[39;00m p_per_1 \u001b[39m==\u001b[39m p_per_1_expected, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected periodic likelihood = \u001b[39m\u001b[39m{\u001b[39;00mp_per_1_expected\u001b[39m}\u001b[39;00m\u001b[39m for test case 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp_per_1\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000013?line=131'>132</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mround(p_per_2,\u001b[39m7\u001b[39m) \u001b[39m==\u001b[39m p_per_2_expected, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected periodic likelihood = \u001b[39m\u001b[39m{\u001b[39;00mp_per_2_expected\u001b[39m}\u001b[39;00m\u001b[39m for test case 2, but got \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mround(p_per_2,\u001b[39m7\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000013?line=133'>134</a>\u001b[0m \u001b[39m# false positive likelihood assertions\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000013?line=134'>135</a>\u001b[0m \u001b[39massert\u001b[39;00m p_fp_1 \u001b[39m==\u001b[39m p_fp_1_expected, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected false posiive likelihood = \u001b[39m\u001b[39m{\u001b[39;00mp_fp_1_expected\u001b[39m}\u001b[39;00m\u001b[39m for test case 1, but got \u001b[39m\u001b[39m{\u001b[39;00mp_fp_1\u001b[39m}\u001b[39;00m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Expected periodic likelihood = 0.0014068 for test case 2, but got 0.0004372 instead"
     ]
    }
   ],
   "source": [
    "def execute_all_tests():    \n",
    "    test_nd_array_check()\n",
    "    test_arr_length_check()\n",
    "    test_len()\n",
    "    test_shape()\n",
    "    test_as_matrix()\n",
    "    test_particle_container_properties()\n",
    "    test_periodic_likelihood_no_noise()\n",
    "    test_periodic_likelihood_with_noise()\n",
    "    test_event_provenance_sampling()\n",
    "    test_particle_resampling()\n",
    "    print(\"All tests passed\")\n",
    "\n",
    "execute_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=7'>8</a>\u001b[0m     res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(res)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=11'>12</a>\u001b[0m test_on_strictly_periodic_signal()\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 16'\u001b[0m in \u001b[0;36mtest_on_strictly_periodic_signal\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=4'>5</a>\u001b[0m conf \u001b[39m=\u001b[39m Config(signal\u001b[39m=\u001b[39msignal, num_particles\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m PeriodicityParticleFilter(config\u001b[39m=\u001b[39mconf)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=7'>8</a>\u001b[0m res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000016?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 12'\u001b[0m in \u001b[0;36mPeriodicityParticleFilter.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=388'>389</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialise_samples()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=390'>391</a>\u001b[0m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignal():\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=391'>392</a>\u001b[0m     \u001b[39m# sample next set of particles from hypothesis distribution p(h_i|h_{i-1})\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=392'>393</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_hypothesis(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_h)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=394'>395</a>\u001b[0m     \u001b[39m# likelihood weighting - compute likeliness of each particle\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=395'>396</a>\u001b[0m     lw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood_weighting(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h)\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 12'\u001b[0m in \u001b[0;36mPeriodicityParticleFilter.update_hypothesis\u001b[1;34m(self, y, h)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=289'>290</a>\u001b[0m \u001b[39m# we need to adjust for noise rate param lambda as this needs to be greater than zero\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=290'>291</a>\u001b[0m h\u001b[39m.\u001b[39mLambda \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_cauchy_1D(h\u001b[39m.\u001b[39mLambda, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms_cauchy)\u001b[39m.\u001b[39mclip(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=292'>293</a>\u001b[0m rsampled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_event_provenance(y, h)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=293'>294</a>\u001b[0m r_is_1_idx, r_is_0_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(rsampled), np\u001b[39m.\u001b[39mnonzero(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mrsampled)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=294'>295</a>\u001b[0m h\u001b[39m.\u001b[39mX[r_is_1_idx] \u001b[39m=\u001b[39m y \n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 12'\u001b[0m in \u001b[0;36mPeriodicityParticleFilter.sample_event_provenance\u001b[1;34m(self, y, h)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=245'>246</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_event_provenance\u001b[39m(\u001b[39mself\u001b[39m, y, h:Particles):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=246'>247</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=247'>248</a>\u001b[0m \u001b[39m    Sample event provenance r_i. \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=248'>249</a>\u001b[0m \u001b[39m    Args: \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=258'>259</a>\u001b[0m \u001b[39m    p(ri = 0 | yi, hi) = 1 - p(ri = 1 | yi, hi)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=259'>260</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=261'>262</a>\u001b[0m     ps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_periodic_likelihood(y, h)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=262'>263</a>\u001b[0m     fp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_false_positive_likelihood(y, h)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=264'>265</a>\u001b[0m     p \u001b[39m=\u001b[39m ps \u001b[39m/\u001b[39m (ps \u001b[39m+\u001b[39m fp)\n",
      "\u001b[1;32md:\\Workspace\\PeriodicEventDetection\\Research.ipynb Cell 12'\u001b[0m in \u001b[0;36mPeriodicityParticleFilter.get_periodic_likelihood\u001b[1;34m(self, y, h)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=300'>301</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=301'>302</a>\u001b[0m \u001b[39mThe likelihood of the signal being generated by the signal process. \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=302'>303</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=308'>309</a>\u001b[0m \u001b[39m    h : particle object containing current parameter hypotheses \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=309'>310</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=311'>312</a>\u001b[0m \u001b[39m# p(yi | hi, ri=1) = N(Ti + x_{i-1}, sigma_i)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=312'>313</a>\u001b[0m p1 \u001b[39m=\u001b[39m norm\u001b[39m.\u001b[39mpdf(y, h\u001b[39m.\u001b[39;49mT \u001b[39m+\u001b[39;49m h\u001b[39m.\u001b[39;49mX_last, h\u001b[39m.\u001b[39mSigma)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=314'>315</a>\u001b[0m \u001b[39m# 1 - F(yi - z_{i-1}; exp(lambda_i)); F_exp(x; lambda) = 1 - exp(-lamba * x)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=315'>316</a>\u001b[0m \u001b[39m# therefore, 1 - F(yi - z_{i-1}; exp(lambda_i)) = exp(-lambda * (yi - z_{i-1}))\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Workspace/PeriodicEventDetection/Research.ipynb#ch0000011?line=316'>317</a>\u001b[0m p2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mh\u001b[39m.\u001b[39mLambda \u001b[39m*\u001b[39m (y \u001b[39m-\u001b[39m h\u001b[39m.\u001b[39mZ_last))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "### Integration + Functionality Tests ###\n",
    "\n",
    "def test_on_strictly_periodic_signal(): \n",
    "    signal = test_data.strict_periodicity\n",
    "    conf = Config(signal=signal, num_particles=1000)\n",
    "    model = PeriodicityParticleFilter(config=conf)\n",
    "\n",
    "    res = model.fit()\n",
    "\n",
    "    print(res)\n",
    "\n",
    "test_on_strictly_periodic_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfcdbabd5fc327726309f0a35dbd35e3b47cda59a0620cb56d1e5f6a943be705"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
